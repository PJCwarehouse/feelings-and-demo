获取网页
requests发起网络请求
1.网络请求的概念
(1)请求：浏览器向网页所在服务器发送一个请求
(2)响应：服务器接受浏览器请求后进行处理，返回响应内容
(3)URL：互联网资源的地址(网址/链接)
(4)HTTP和HTTPS：网络传输数据到本地浏览器的传送协议
2.requests库
(1)requests.get(url).向指定URL发起get请求，返回结果是一个包含响应内容的response对象，里面有各种响应信息
(2)response对象
status_code属性，表示服务器的响应状态，200代表服务器正常响应，404代表页面未找到
text属性，查看具体的响应内容
encoding属性，响应内容编码格式
Urllib发送网络请求

Urllib 库，它是 Python 内置的 HTTP 请求库，也就是说不需要额外安装即可使用，它包含四个模块：

第一个模块 request，它是最基本的 HTTP 请求模块，我们可以用它来模拟发送一请求，就像在浏览器里输入网址然后敲击回车一样，只需要给库方法传入 URL 还有额外的参数，就可以模拟实现这个过程了。

第二个 error 模块即异常处理模块，如果出现请求错误，我们可以捕获这些异常，然后进行重试或其他操作保证程序不会意外终止。

第三个 parse 模块是一个工具模块，提供了许多 URL 处理方法，比如拆分、解析、合并等等的方法。

第四个模块是 robotparser，主要是用来识别网站的 robots.txt 文件，然后判断哪些网站可以爬，哪些网站不可以爬的，其实用的比较少。